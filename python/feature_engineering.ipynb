{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Testing\n",
    "In this part, we will take a look at our variables and determine which feature engineering methods prep our data in a way that is easier for our models to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "white_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv\"\n",
    "\n",
    "red_df = pd.read_csv(red_url, sep=\";\")\n",
    "white_df = pd.read_csv(white_url, sep=\";\")\n",
    "red_df[\"is_red\"] = 1\n",
    "white_df[\"is_red\"] = 0\n",
    "df_raw = pd.concat([red_df, white_df])\n",
    "df_raw.columns = [x.replace(\" \", \"_\") for x in df_raw.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train_raw, df_test_raw = train_test_split(df_raw, test_size=0.3, random_state=55, stratify=df_raw[\"quality\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auc(df, n_iters=250, target=\"quality\", split=0.4):\n",
    "    auc_list = []\n",
    "    for seed in range(n_iters):\n",
    "        X = df.drop(target, axis=1)\n",
    "        y = pd.Categorical(df[target], ordered=True)\n",
    "        \n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=split, random_state=seed, stratify=y)\n",
    "        \n",
    "        phat = LogisticRegression(max_iter=5000, solver=\"saga\")\\\n",
    "            .fit(X_train, y_train)\\\n",
    "            .predict_proba(X_val)\n",
    "        auc_list.append(roc_auc_score(y_val, phat, multi_class=\"ovo\")) \n",
    "    return auc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "cols_to_adjust = [x for x in df_raw.columns if x not in ['quality', 'is_red']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformer(df, scaler, cols_adj=cols_to_adjust, cols=df_raw.columns):\n",
    "    transform = ColumnTransformer([(' ', scaler, cols_adj)], remainder='passthrough')\n",
    "    return pd.DataFrame(transform.fit_transform(df), columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results = get_auc(df_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std_train = data_transformer(df_train_raw, preprocessing.StandardScaler())\n",
    "\n",
    "std_scale_results = get_auc(df_std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_max = data_transformer(df_train_raw, preprocessing.MinMaxScaler())\n",
    "\n",
    "min_max_results = get_auc(df_min_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_robust_scaler = data_transformer(df_train_raw, preprocessing.RobustScaler(quantile_range=(.2, .8)))\n",
    "# Drops outliers\n",
    "robscale_results = get_auc(df_robust_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:3251: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    }
   ],
   "source": [
    "df_pwr_transform = data_transformer(df_train_raw, preprocessing.PowerTransformer())\n",
    "#  yao johnson\n",
    "pwr_transform_results = get_auc(df_pwr_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quantile_transfmr = data_transformer(df_train_raw, preprocessing.QuantileTransformer())\n",
    "\n",
    "quant_transfmr_results = get_auc(df_quantile_transfmr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beepy import beep\n",
    "beep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_zip = zip(baseline_results, std_scale_results, min_max_results, robscale_results, pwr_transform_results, quant_transfmr_results)\n",
    "\n",
    "pd.DataFrame(res_zip).to_csv(\"../result_logs/transformations.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
