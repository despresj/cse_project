{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "df = pd.read_csv(\"../data/processed/wine_data_combined.csv\")\n",
    "cols_to_adjust = [x for x in df.columns if x not in [\"quality\", \"is_red\"]]\n",
    "model_path = \"../saved_models_testing/\"\n",
    "retrain = True  # Set to True and rerun the model gridsearches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rm dooops\n",
    "df = df.groupby(df.columns.tolist()).size().reset_index().\\\n",
    "    rename(columns={0:'records'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "add: knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logistic_reg = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", tol=1e-2, max_iter=500)\n",
    "\n",
    "\n",
    "# params_logistic = {\"C\": np.logspace(-5, 0, 100), \"penalty\": [\"l1\", \"l2\"]}\n",
    "params_logistic = {\"l1\": np.logspace(-5, 0, 25),\n",
    "                \"l2\": np.logspace(-5, -2, 25)}\n",
    "\n",
    "logistic_grid_search = model_selection.GridSearchCV(\n",
    "    multi_logistic_reg, params_logistic, n_jobs=cores)\n",
    "# Not all of these converge given the low tolerance I set above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df, test_size=0.3, random_state=55, stratify=df[\"quality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "stratified = model_selection.StratifiedKFold()\n",
    "df_transform = ColumnTransformer(\n",
    "    [(\" \", StandardScaler(), cols_to_adjust)],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "df_train = pd.DataFrame(df_transform.fit_transform(df_train), columns=df.columns)\n",
    "X_train = df_train.drop(\"quality\", axis=1)\n",
    "y_train = pd.Categorical(df_train[\"quality\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scaled = X_train[[\"is_red\", \"records\"]].to_numpy()\n",
    "scaled = X_train.drop([\"is_red\", \"records\"], axis=1)\n",
    "\n",
    "# anything 3x larger than scaled iqr is gona get replaced\n",
    "# by a knn inpute\n",
    "upper_quartile = np.quantile(scaled, 0.75, axis=0) * 2\n",
    "scaled = np.where(scaled > upper_quartile, np.nan, scaled)\n",
    "lower_quartile = np.quantile(scaled, 0.25, axis=0) * 2\n",
    "scaled = np.where(scaled < lower_quartile, np.nan, scaled)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "inputed = imputer.fit_transform(scaled)\n",
    "\n",
    "X_train = np.concatenate((inputed, already_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.DataFrame(df_transform.fit_transform(df_test), columns=df.columns)\n",
    "X_test = df_test.drop(\"quality\", axis=1)\n",
    "y_test = pd.Categorical(df_test[\"quality\"], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "already_scaled = X_test[[\"is_red\", \"records\"]].to_numpy()\n",
    "scaled = X_test.drop([\"is_red\", \"records\"], axis=1)\n",
    "\n",
    "# anything 3x larger than scaled iqr is gona get replaced\n",
    "# by a knn inpute\n",
    "scaled = np.where(scaled > upper_quartile, np.nan, scaled)\n",
    "scaled = np.where(scaled < lower_quartile, np.nan, scaled)\n",
    "\n",
    "inputed = imputer.fit_transform(scaled)\n",
    "\n",
    "X_test = np.concatenate((inputed, already_scaled), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    \"max_depth\": np.arange(3, 20, 2),\n",
    "    \"colsample_bytree\": np.arange(0.5, 1, 0.1),\n",
    "    \"learning_rate\": np.logspace(-5, -1, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xgb_grid_search = model_selection.GridSearchCV(\n",
    "    xgboost, params_xgb, n_jobs=cores, cv=stratified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9030612244897959"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if retrain:\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(xgb_grid_search, f\"{model_path}xgb_grid_search.joblib\")\n",
    "\n",
    "xgb_grid_search = joblib.load(f\"{model_path}xgb_grid_search.joblib\")\n",
    "xgb_best_params = xgb.XGBClassifier(**xgb_grid_search.best_params_, probability=True)\n",
    "models = []\n",
    "models.append((\"xgb\", xgb_best_params))\n",
    "\n",
    "np.sum(\n",
    "    xgb_best_params.fit(X_train, y_train).predict(X_train) == y_train\n",
    ") / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959759688099675"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = xgb_best_params.predict_proba(X_train)\n",
    "metrics.roc_auc_score(y_train, yhat, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomeal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logistic_reg = LogisticRegression(solver=\"saga\", tol=1e-2, max_iter=500)\n",
    "params_logistic = {\"C\": np.logspace(-5, 0, 100), \"penalty\": [\"l1\", \"l2\"]}\n",
    "logistic_grid_search = model_selection.GridSearchCV(\n",
    "    multi_logistic_reg, params_logistic, n_jobs=cores, cv=stratified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Not all of these converge given the low tolerance I set above\n",
    "if retrain:\n",
    "    logistic_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(logistic_grid_search, \"../saved_models/logistc_grid_search.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_grid_search = joblib.load(f\"{model_path}logistc_grid_search.joblib\")\n",
    "logistic_best_params = LogisticRegression(\n",
    "    **logistic_grid_search.best_params_, solver=\"saga\", tol=1e-2, max_iter=500\n",
    "\n",
    ")\n",
    "models.append((\"logistic_reg\", logistic_best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = logistic_best_params.fit(X_train, y_train).predict(X_train)\n",
    "yhat = pd.Categorical(df_train[\"quality\"], ordered=True)\n",
    "np.sum(\n",
    "    yhat == y_train\n",
    ") / X_train.shape[0]\n",
    "yhat = logistic_best_params.fit(X_train, y_train).predict_proba(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5271213748657357"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(logistic_best_params.predict(X_train) == y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792262440547716"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.roc_auc_score(y_train, yhat, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine = svm.SVC(gamma=\"auto\", probability=True, kernel=\"rbf\")\n",
    "params_svm = {\"C\": np.logspace(-3, 3, 500)}\n",
    "svm_grid_search = model_selection.GridSearchCV(\n",
    "    support_vector_machine, params_svm, n_jobs=cores, cv=stratified\n",
    ")\n",
    "if retrain:\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(svm_grid_search, f\"{model_path}svm_gridsearch.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393602864065928"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_search = joblib.load(f\"{model_path}svm_gridsearch.joblib\")\n",
    "svm_best_params = svm.SVC(\n",
    "    gamma=\"auto\", probability=True\n",
    ")\n",
    "svm_best_params.fit(X_train, y_train)\n",
    "models.append((\"svm\", svm_best_params))\n",
    "np.sum(svm_best_params.predict(X_train) == y_train) / X_train.shape[0]\n",
    "\n",
    "\n",
    "metrics.roc_auc_score(y_train, svm_best_params.predict_proba(X_train), multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5601503759398496"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(svm_best_params.predict(X_train) == y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(models, voting=\"soft\")\n",
    "\n",
    "if retrain:\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    joblib.dump(ensemble, f\"{model_path}ensemble.joblib\")\n",
    "\n",
    "ensemble = joblib.load(f\"{model_path}ensemble.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagging = BaggingClassifier(base_estimator=ensemble, n_estimators=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = bagging.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5628356605800214"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = bagging.predict(X_train)\n",
    "np.sum(yhat == y_train)/ len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = bagging.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.543859649122807"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(xgb_best_params.predict(X_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576441102756893"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(bagging.predict(X_test) == y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5576441102756893"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(yhat == y_test)/ len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "conf = list(confusion_matrix(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1588232010.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/0n/gp39qxl100149ccbr1n65kzh0000gn/T/ipykernel_67789/1588232010.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    pipeline.fit(,)\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "if not retrain:\n",
    "    pipeline = Pipeline([(\"scaler\", df_transform), (\"bag\", bagging)])\n",
    "    pipeline.fit(,)\n",
    "    joblib.dump(pipeline, f\"{model_path}pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/base.py:441: UserWarning: X does not have valid feature names, but BaggingClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7322771213748658"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = joblib.load(f\"{model_path}pipeline.joblib\")\n",
    "np.sum(pipeline.predict(X_train) == y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
