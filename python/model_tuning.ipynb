{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import model_selection\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/wine_data_combined.csv\")\n",
    "cols_to_adjust = [x for x in df.columns if x not in [\"quality\", \"is_red\"]]\n",
    "model_path = \"../saved_models/\"\n",
    "retrain = True  # Set to True and rerun the model gridsearches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "add: knn, naieve bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df, test_size=0.3, random_state=55, stratify=df[\"quality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "stratified = model_selection.StratifiedKFold()\n",
    "df_transform = ColumnTransformer(\n",
    "    [(\" \", StandardScaler(), cols_to_adjust)],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "df_train = pd.DataFrame(df_transform.fit_transform(df_train), columns=df.columns)\n",
    "X_train = df_train.drop(\"quality\", axis=1)\n",
    "y_train = pd.Categorical(df_train[\"quality\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {'max_depth': np.arange(3, 20, 2),\n",
    "             'colsample_bytree' : np.arange(0.5, 1, 0.1),\n",
    "             'gamma': np.arange(1, 9, 0.1),\n",
    "             \"learning_rate\": np.logspace(-5, -1, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xgb_grid_search = model_selection.GridSearchCV(\n",
    "    xgboost, params_xgb, n_jobs=cores, cv=stratified\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "if retrain:\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(xgb_grid_search, f\"{model_path}xgb_grid_search.joblib\")\n",
    "\n",
    "xgb_grid_search = joblib.load(f\"{model_path}xgb_grid_search.joblib\")\n",
    "xgb_best_params = xgb.XGBClassifier(**xgb_grid_search.best_params_)\n",
    "models = []\n",
    "models.append((\"xgb\", xgb_best_params))\n",
    "\n",
    "np.sum(xgb_best_params.fit(X_train, y_train).predict(X_train) == y_train) / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomeal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logistic_reg = LogisticRegression(solver=\"saga\", tol=1e-2, max_iter=500)\n",
    "params_logistic = {\"C\": np.logspace(-5, 0, 100), \"penalty\": [\"l1\", \"l2\"]}\n",
    "logistic_grid_search = model_selection.GridSearchCV(\n",
    "    multi_logistic_reg, params_logistic, n_jobs=cores, cv=stratified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Not all of these converge given the low tolerance I set above\n",
    "if retrain:\n",
    "    logistic_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(logistic_grid_search, \"../saved_models/logistc_grid_search.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5396965031889158"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_grid_search = joblib.load(f\"{model_path}logistc_grid_search.joblib\")\n",
    "logistic_best_params = LogisticRegression(\n",
    "    **logistic_grid_search.best_params_, solver=\"saga\", tol=1e-2, max_iter=500\n",
    ")\n",
    "models.append((\"logistic_reg\", logistic_best_params))\n",
    "\n",
    "np.sum(logistic_best_params.fit(X_train, y_train).predict(X_train) == y_train) / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine = svm.SVC()\n",
    "params_svm = {'C': np.logspace(-3, 3, 50), 'gamma': np.logspace(1, -5, 50), 'kernel': ['rbf',  'sigmoid']}\n",
    "svm_grid_search = model_selection.GridSearchCV(support_vector_machine, params_svm, n_jobs=cores, cv=stratified)\n",
    "if retrain:\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(svm_grid_search, f\"{model_path}svm_gridsearch.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_grid_search = joblib.load(f\"{model_path}svm_gridsearch.joblib\")\n",
    "svm_best_params = svm.SVC(**svm_grid_search.best_params_)\n",
    "np.sum(svm_grid_search.predict(X_train) == y_train) / X_train.shape[0]\n",
    "models.append((\"svm\", svm_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35363976248075657"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "params_gnb = {'var_smoothing': np.logspace(0,-9, num=1000)}\n",
    "gnb = GaussianNB()\n",
    "nb_search = model_selection.GridSearchCV(gnb, params_gnb, n_jobs=cores, cv=stratified)\n",
    "\n",
    "if retrain:\n",
    "    nb_search.fit(X_train, y_train)\n",
    "    joblib.dump(nb_search, f\"{model_path}gnb.joblib\")\n",
    "nb_search = joblib.load(f\"{model_path}gnb.joblib\")\n",
    "models.append((\"gnb\", gnb))\n",
    "np.sum(gnb.fit(X_train, y_train).predict(X_train) == y_train) / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(models, voting=\"soft\")\n",
    "\n",
    "if retrain:\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    joblib.dump(ensemble, f\"{model_path}ensemble.joblib\")\n",
    "\n",
    "ensemble = joblib.load(f\"{model_path}ensemble.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "if retrain:\n",
    "    pipeline = Pipeline([(\"scaler\", df_transform), (\"ensemble\", ensemble)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    joblib.dump(pipeline, f\"{model_path}pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34154387508247197"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = joblib.load(f\"{model_path}pipeline.joblib\")\n",
    "np.sum(pipeline.fit(X_train, y_train).predict(X_train) == y_train) / X_train.shape[0]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit ('my_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
