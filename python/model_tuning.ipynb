{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn import model_selection\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/wine_data_combined.csv\")\n",
    "cols_to_adjust = [x for x in df.columns if x not in [\"quality\", \"is_red\"]]\n",
    "model_path = \"../saved_models/\"\n",
    "retrain = True  # Set to True and rerun the model gridsearches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "add: knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = model_selection.train_test_split(\n",
    "    df, test_size=0.3, random_state=55, stratify=df[\"quality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "stratified = model_selection.StratifiedKFold()\n",
    "df_transform = ColumnTransformer(\n",
    "    [(\" \", StandardScaler(), cols_to_adjust)],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "df_train = pd.DataFrame(df_transform.fit_transform(df_train), columns=df.columns)\n",
    "X_train = df_train.drop(\"quality\", axis=1)\n",
    "y_train = pd.Categorical(df_train[\"quality\"], ordered=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb = {\n",
    "    \"max_depth\": np.arange(3, 20, 2),\n",
    "    \"colsample_bytree\": np.arange(0.5, 1, 0.1),\n",
    "    \"learning_rate\": np.logspace(-5, -1, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost = xgb.XGBClassifier()\n",
    "xgb_grid_search = model_selection.GridSearchCV(\n",
    "    xgboost, params_xgb, n_jobs=cores, cv=stratified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if retrain:\n",
    "    xgb_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(xgb_grid_search, f\"{model_path}xgb_grid_search.joblib\")\n",
    "\n",
    "xgb_grid_search = joblib.load(f\"{model_path}xgb_grid_search.joblib\")\n",
    "xgb_best_params = xgb.XGBClassifier(**xgb_grid_search.best_params_, probability=True)\n",
    "models = []\n",
    "models.append((\"xgb\", xgb_best_params))\n",
    "\n",
    "np.sum(\n",
    "    xgb_best_params.fit(X_train, y_train).predict(X_train) == y_train\n",
    ") / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomeal Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_logistic_reg = LogisticRegression(solver=\"saga\", tol=1e-2, max_iter=500)\n",
    "params_logistic = {\"C\": np.logspace(-5, 0, 100), \"penalty\": [\"l1\", \"l2\"]}\n",
    "logistic_grid_search = model_selection.GridSearchCV(\n",
    "    multi_logistic_reg, params_logistic, n_jobs=cores, cv=stratified\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Not all of these converge given the low tolerance I set above\n",
    "if retrain:\n",
    "    logistic_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(logistic_grid_search, \"../saved_models/logistc_grid_search.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_grid_search = joblib.load(f\"{model_path}logistc_grid_search.joblib\")\n",
    "logistic_best_params = LogisticRegression(\n",
    "    **logistic_grid_search.best_params_, solver=\"saga\", tol=1e-2, max_iter=500\n",
    ")\n",
    "models.append((\"logistic_reg\", logistic_best_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephdespres/my_env/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "support_vector_machine = svm.SVC(gamma=\"auto\", probability=True)\n",
    "params_svm = {\"C\": np.logspace(-3, 3, 5), \"kernel\": [\"rbf\", \"sigmoid\"]}\n",
    "svm_grid_search = model_selection.GridSearchCV(\n",
    "    support_vector_machine, params_svm, n_jobs=cores, cv=stratified\n",
    ")\n",
    "if retrain:\n",
    "    svm_grid_search.fit(X_train, y_train)\n",
    "    joblib.dump(svm_grid_search, f\"{model_path}svm_gridsearch.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0n/gp39qxl100149ccbr1n65kzh0000gn/T/ipykernel_23968/792677330.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  np.sum(svm_best_params.predict_proba(X_train) == y_train) / X_train.shape[0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid_search = joblib.load(f\"{model_path}svm_gridsearch.joblib\")\n",
    "svm_best_params = svm.SVC(\n",
    "    **svm_grid_search.best_params_, gamma=\"auto\", probability=True\n",
    ")\n",
    "svm_best_params.fit(X_train, y_train)\n",
    "models.append((\"svm\", svm_best_params))\n",
    "np.sum(svm_best_params.predict_proba(X_train) == y_train) / X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(models, voting=\"soft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('xgb',\n",
       "                              XGBClassifier(colsample_bytree=0.5, max_depth=13,\n",
       "                                            missing=nan,\n",
       "                                            objective='multi:softprob',\n",
       "                                            probability=True)),\n",
       "                             ('logistic_reg',\n",
       "                              LogisticRegression(C=0.03430469286314919,\n",
       "                                                 max_iter=500, solver='saga',\n",
       "                                                 tol=0.01)),\n",
       "                             ('svm',\n",
       "                              SVC(C=31.622776601683793, gamma='auto',\n",
       "                                  probability=True))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble = VotingClassifier(models, voting=\"soft\")\n",
    "\n",
    "if retrain:\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    joblib.dump(ensemble, f\"{model_path}ensemble.joblib\")\n",
    "\n",
    "ensemble = joblib.load(f\"{model_path}ensemble.joblib\")\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "if retrain:\n",
    "    pipeline = Pipeline([(\"scaler\", df_transform), (\"ensemble\", ensemble)])\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    joblib.dump(pipeline, f\"{model_path}pipeline.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7., 5., 5., ..., 5., 6., 6.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = joblib.load(f\"{model_path}pipeline.joblib\")\n",
    "pipeline.predict(X_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "46adb795152d5db59f955a662f1f645c8cf39f91042255151212cfaad4a46d3d"
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
